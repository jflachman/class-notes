# DU AI Bootcamp Windows WSL Tool Setup

### DU Class Notes Table of Contents

----------------------------------------------

-   [Course Overview](README.md)
-   [Tool Setup](1_DU_tool_setup.md)
    -   [Tool Setup - Mac](1.1_DU_tool_setup_mac.md)
    -   [Tool Setup - Windows](1.2_DU_tool_setup_windows.md)
        -   [Windows - alternate setup using wsl](1.2.1_DU_windows_alternate_install_using_wsl.md)
        -   [Tool Setup - Windows WSL](1.2.2_DU_tool_setup_wsl.md)
        -   [Window - alternative setup using docker](1.2.3_DU_tool_setup_docker.md)

-   [Online Research Tips](2_online_research_tips.md)
-   [Further Reading and Helpful Links](3_further_reading_and_helpful_links.md)
    -   [Cheatsheets & Tips](3.1_cheatsheets_and_tips.md)
        -   [Scientific python cheatsheet by IPGD](3.1.1_scientific_python_cheat_sheet_by_IPGP.md)
        -   [Useful Python tips](3.1.2_useful_python.md)
    -   [Books](3.2_books.md)
    -   [Articles](3.3_articles.md)
    -   [Subscriptions](3.4_subscriptions)
-   [Career Engagement](4_career_engagement.md)

----------------------------------------------

# Step 1: Install & Configure Podman

1. Install WSL2 (Follow windows instructions)
2. Install Podman (windows installer: https://podman.io/docs/installation)
3. Install Podman Desktop (windows installer: https://podman-desktop.io/docs/installation)
4. Install CUDA support in Podman (**DO THIS STEP IF YOU WISH TO USE YOUR GPU FOR CALCULATIONS**)
    1. Follow these instructions from rootfs:  https://github.com/containers/podman/issues/19005
    2. Open windows terminal in podman vm in WSL2  (podman_machine_default)

        ```
        curl -s -L https://nvidia.github.io/libnvidia-container/stable/rpm/nvidia-container-toolkit.repo | sudo tee /etc/yum.repos.d/nvidia-container-toolkit.repo
        
        sudo yum install -y nvidia-container-toolkit
        
        sudo nvidia-ctk cdi generate --output=/etc/cdi/nvidia.yaml
        
        nvidia-ctk cdi list`
        ```

    3. Test

        ```
        podman run --device nvidia.com/gpu=all nvcr.io/nvidia/k8s/cuda-sample:nbody nbody -benchmark -gpu
        ```

# Step 2: Pull a container:
Pull container from either location:  (https://docs.podman.io/en/v4.4/markdown/podman-run.1.html)
1. https://hub.docker.com/r/tensorflow/tensorflow/
    - Tags: https://hub.docker.com/r/tensorflow/tensorflow/tags/  (latest-gpu-jupyter)
    - Source Dockerfiles:  https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/tf_sig_build_dockerfiles
    - `tensorflow/tensorflow:latest-gpu-jupyter`
   -  `docker pull tensorflow/tensorflow:latest-gpu-jupyter`
2. https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html
    - https://quay.io/jupyter/tensorflow-notebook:cuda-latest

    ` podman pull quay.io/jupyter/tensorflow-notebook:cuda-latest`
        
# Step 3: Start the container
- Podman Example: Given:  Local directory   `C:\ML\DU\repos`.  Default working directory `jovyan`:

    `podman run -it -v "C:\ML\DU\repos":/home/jovyan/work -p 8888:8888 tensorflow/tensorflow:latest-gpu python`

    `podman run --gpus all -it --rm -p 8888:8888 tensorflow/tensorflow:latest-gpu-jupyter`

    `podman run --gpus all -it --rm -v /mnt/c/ML/DU/repos/temp:/tf  -p 8888:8888 tensorflow/tensorflow:latest-gpu-jupyter`

    `podman run --gpus all -it --rm -v /mnt/c/ML/DU/repos:/tf  -p 8888:8888 tensorflow/tensorflow:latest-gpu-jupyter &`

- Docker Example:  
    `docker run -it --rm -v $(realpath ~/notebooks):/tf/notebooks -p 8888:8888 tensorflow/tensorflow:latest-jupyter`

    `docker run --gpus all -it --rm -d -v C:/ML/DU/repos:/tf  -p 8888:8888 tensorflow/tensorflow:latest-gpu-jupyter`

    `docker run --gpus all -it --rm -d -v C:/ML/DU/repos:/home/jovyan/work  -p 8888:8888 quay.io/jupyter/tensorflow-notebook:cuda-latest`

- **NOTES** Podman run parameters
    - `--volume`, `-v`=[[SOURCE-VOLUME|HOST-DIR:]CONTAINER-DIR[:OPTIONS]]
    - `--tty, -t : Allocate a pseudo-TTY. The default is false.
    - `--interactive`, `-I` : When set to true, keep stdin open even if not attached. The default is false.
    - `--rm` : Automatically remove the container when it exits. The default is false.
    - `--workdir`, `-w`:  Working directory inside the container

# Step 4: Running 

- Open a notebook and click on the kernel selector (or open the Command Palette `(Cntrl+Shift+P)` then select `Notebook: Select Notebook Kernel`
- Select `Select Another Kernel`
- Select `Jupyter Server from Docker Containers`
- Select a container image for your project (currently, the Scientific Python Stack is supported)
- Select the kernel from the container image (e.g., Python 3)

# Step 5:  Attach Windows VSCode to Podman container
- https://medium.com/@FredAsDev/connect-vs-code-jupyter-notebook-to-a-jupyter-container-a63293f29325
- https://stackoverflow.com/questions/77167514/how-to-attach-visual-studio-code-terminal-to-a-podman-container
- https://docs.podman.io/en/latest/markdown/podman-system-service.1.html
- https://stackoverflow.com/questions/77167514/how-to-attach-visual-studio-code-terminal-to-a-podman-container

# Notes: Running Containers (different container versions)

## Start a CPU-only container

```
$ docker run -it --rm tensorflow/tensorflow bash
```


___

## Start a GPU container, using the Python interpreter.
```
$ docker run -it --rm --runtime=nvidia tensorflow/tensorflow:latest-gpu python
```



___
## Run a Jupyter notebook server with your own notebook directory:

Own notebook directory assumed here to be `~/notebooks`. To use it, navigate to `localhost:8888` in your browser.

```
$ docker run -it --rm -v $(realpath ~/notebooks):/tf/notebooks -p 8888:8888 tensorflow/tensorflow:latest-jupyter
```



# Other references:
- https://github.com/orgs/tensorflow/repositories?type=all
- https://hub.docker.com/r/tensorflow/tensorflow/
- https://hub.docker.com/r/tensorflow/build
- https://hub.docker.com/layers/tensorflow/tensorflow/latest-gpu-jupyter/images/sha256-efc25f8ad0ec337e8f4e2de9e7e8e391e6729481c7a7cae4bdea3137da7822c6?context=explore

# Other install instructions:
- https://www.tensorflow.org/install/docker
- https://docs.docker.com/reference/cli/docker/container/run/#volume
- https://discussion.fedoraproject.org/t/how-to-run-tensorflow-gpu-in-podman/74060
- https://github.com/containers/podman/issues/19005
- https://phoenixnap.com/kb/podman-vs-docker#:~:text=The%20Docker's%20architecture%20requires%20the,do%20not%20require%20superuser%20privileges.
- https://phoenixnap.com/blog/what-is-container-orchestration
    
